{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:35:22.343772835Z",
     "start_time": "2023-10-24T17:35:22.332266051Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepsig'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdeepsig\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m display\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'deepsig'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import deepsig\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T17:35:22.338030112Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_csv_files_from_folder(folder_path):\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Get a list of files in the folder\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    # Iterate through the files in the folder\n",
    "    for file_name in file_list:\n",
    "        # Check if the file has a .csv extension\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Append the DataFrame to the list\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['dataset', 'method', 'fitness_rule', 'fitness', 'ACC', 'MCC', 'f1_score', 'avg_odds_diff', 'stat_par_diff', 'eq_opp_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = read_csv_files_from_folder('results/')\n",
    "results.replace({'ftl_mlp_initializer': 'Fair Transition Loss', 'adversarial_debiasing_initializer': 'Adversarial Debiasing', 'gerry_fair_classifier_initializer': 'Gerry Fair Classifier', 'prejudice_remover_initializer': 'Prejudice Remover', 'simple_mlp_initializer': 'Standard MLP (baseline)'}, inplace=True)\n",
    "results.replace({'adult_dataset_reader': 'Adult Income', 'compas_dataset_reader': 'Compas Recidivism', 'german_dataset_reader': 'German Credit', 'bank_dataset_reader': 'Bank Marketing'}, inplace=True)\n",
    "results.rename(columns={'avg_odds_diff': 'Equalized Odds', 'stat_par_diff': 'Statistical Parity', 'eq_opp_diff': 'Equal Opportunity', 'MCC': 'Mathew Correlation', 'ACC': 'Accuracy'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_rules_target_metrics = {\n",
    "    'mcc_parity': {'performance': 'Mathew Correlation', 'fairness': 'Statistical Parity'},\n",
    "    'mcc_opportunity': {'performance': 'Mathew Correlation', 'fairness': 'Equal Opportunity'},\n",
    "    'mcc_odds': {'performance': 'Mathew Correlation', 'fairness': 'Equalized Odds'},\n",
    "    'acc_parity': {'performance': 'Accuracy', 'fairness': 'Statistical Parity'},\n",
    "    'acc_opportunity': {'performance': 'Accuracy', 'fairness': 'Equal Opportunity'},\n",
    "    'acc_odds': {'performance': 'Accuracy', 'fairness': 'Equalized Odds'}\n",
    "}\n",
    "\n",
    "fitness_rules_target_metrics = {\n",
    "    'mcc_parity': ('Mathew Correlation', 'Statistical Parity'),\n",
    "    'mcc_opportunity': ('Mathew Correlation', 'Equal Opportunity'),\n",
    "    'mcc_odds': ('Mathew Correlation', 'Equalized Odds'),\n",
    "    'acc_parity': ('Accuracy', 'Statistical Parity'),\n",
    "    'acc_opportunity': ('Accuracy', 'Equal Opportunity'),\n",
    "    'acc_odds': ('Accuracy', 'Equalized Odds')\n",
    "}\n",
    "fitness_rules_abvr = {\n",
    "    'mcc_parity': 'Max(MCC - Stat. Parity)',\n",
    "    'mcc_opportunity': 'Max(MCC - Eq. Odds)',\n",
    "    'mcc_odds': 'Max(MCC - Eq. Opp.)',\n",
    "    'acc_parity': 'Max(Acc - Stat. Parity)',\n",
    "    'acc_opportunity': 'Max(Acc - Eq. Odds)',\n",
    "    'acc_odds': 'Max(Acc - Eq. Opp.)'\n",
    "}\n",
    "\n",
    "results['Performance'] = 0\n",
    "results['Fairness'] = 0\n",
    "results['Fitness Rule'] = ''\n",
    "for fitness_rule, (performance_metric, fairness_metric) in fitness_rules_target_metrics.items():\n",
    "    results.loc[results.fitness_rule == fitness_rule,'Performance'] = results.loc[results.fitness_rule == fitness_rule,performance_metric]\n",
    "    results.loc[results.fitness_rule == fitness_rule,'Fairness'] = results.loc[results.fitness_rule == fitness_rule,fairness_metric]\n",
    "    results.loc[results.fitness_rule == fitness_rule,'Fitness Rule Abvr'] = fitness_rules_abvr[fitness_rule]\n",
    "    results.loc[results.fitness_rule == fitness_rule,'Fitness Rule'] = 'Max(%s - %s)' % fitness_rules_target_metrics[fitness_rule]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['Adult Income', 'Bank Marketing', 'Compas Recidivism','German Credit']\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_rules = ['mcc_parity', 'mcc_opportunity', 'mcc_odds', 'acc_parity', 'acc_opportunity', 'acc_odds']\n",
    "fitness_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['Standard MLP (baseline)',\n",
    " 'Fair Transition Loss',\n",
    " 'Adversarial Debiasing',\n",
    " 'Prejudice Remover',\n",
    " 'Gerry Fair Classifier']\n",
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.exists('multi_aso_data_list.json'):\n",
    "    with open('multi_aso_data_list.json') as file:\n",
    "        multi_aso_data_list = json.load(file)\n",
    "else:    \n",
    "    multi_aso_data_list = []\n",
    "    for d in datasets:\n",
    "        multi_aso_data = []\n",
    "        for f in fitness_rules:\n",
    "            methods_results = []\n",
    "            for m in methods:\n",
    "                r = results.loc[ (results['dataset'] == d) &\n",
    "                                     (results['fitness_rule'] == f) &\n",
    "                                     (results['method'] == m) ]\\\n",
    "                            .fitness.tolist()\n",
    "                if len(r) == 0:\n",
    "                    r = [-1]\n",
    "                methods_results.append(r)\n",
    "            min_eps = deepsig.multi_aso(methods_results, confidence_level=0.95)\n",
    "            multi_aso_data_list.append({'fitness_rule': f, 'dataset': d, 'min_eps': min_eps.tolist()})\n",
    "    with open('multi_aso_data_list.json', 'w') as file:\n",
    "        json.dump(multi_aso_data_list, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aso_df_resume = []\n",
    "reverse_aso_df_resume = []\n",
    "for aso_result in sorted(multi_aso_data_list, key=lambda x: x['dataset']):\n",
    "    fitness_rule = aso_result['fitness_rule']\n",
    "    dataset = aso_result['dataset']\n",
    "\n",
    "    aso_df = pd.DataFrame(aso_result['min_eps'], columns=methods)\n",
    "    aso_df['method'] = methods\n",
    "    aso_df['dataset'] = dataset\n",
    "    aso_df['fitness_rule'] = fitness_rule\n",
    "    aso_df = aso_df[aso_df['method'] == 'Fair Transition Loss' ]\n",
    "    aso_df = aso_df.drop(['Fair Transition Loss'], axis=1)\n",
    "    aso_df = aso_df.drop(['method'], axis=1)\n",
    "    aso_df_resume.append(aso_df)\n",
    "\n",
    "    reverse_aso_df = pd.DataFrame(aso_result['min_eps'], columns=methods).transpose()\n",
    "    mapping = dict()\n",
    "    for i, m in enumerate(methods):\n",
    "        mapping[reverse_aso_df.columns[i]] = m + ' (reverse)'\n",
    "    reverse_aso_df = reverse_aso_df.rename(columns=mapping)\n",
    "    reverse_aso_df['method'] = methods\n",
    "    reverse_aso_df['dataset'] = dataset\n",
    "    reverse_aso_df['fitness_rule'] = fitness_rule\n",
    "    reverse_aso_df = reverse_aso_df[reverse_aso_df['method'] == 'Fair Transition Loss' ]\n",
    "    reverse_aso_df = reverse_aso_df.drop(['Fair Transition Loss (reverse)'], axis=1)\n",
    "    reverse_aso_df = reverse_aso_df.drop(['method'], axis=1)\n",
    "    reverse_aso_df_resume.append(reverse_aso_df)\n",
    "\n",
    "print('Significance Testing')\n",
    "significance = pd.concat(aso_df_resume)\n",
    "significance = significance.set_index(['fitness_rule', 'dataset'])\n",
    "significance = significance.sort_values(by=['fitness_rule', 'dataset'])\n",
    "display(pd.transpose(significance))\n",
    "formatted_significance = significance.applymap(lambda x: '\\\\textbf{' + f'{x:.2f}' + '}' if x < 0.5 else f'{x:.2f}' )\n",
    "formatted_significance.to_latex('tables/significance_resume.tex')\n",
    "\n",
    "reverse_significance = pd.concat(reverse_aso_df_resume)\n",
    "reverse_significance = reverse_significance.set_index(['fitness_rule', 'dataset'])\n",
    "reverse_significance = reverse_significance.sort_values(by=['fitness_rule', 'dataset'])\n",
    "reverse_formatted_significance = reverse_significance.applymap(lambda x: '\\\\textit{' + f'{x:.2f}' + '}' if x < 0.5 else f'{x:.2f}' )\n",
    "reverse_formatted_significance.to_latex('tables/reverse_significance_resume.tex')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col, rev_col in zip(formatted_significance.columns, reverse_formatted_significance.columns):\n",
    "    formatted_significance[col] = formatted_significance[col] + (' (' + reverse_formatted_significance[rev_col] + ')')\n",
    "formatted_significance.to_latex('tables/combined_significance_resume.tex')\n",
    "formatted_significance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_results = results\\\n",
    "    .groupby(['Fitness Rule Abvr', 'dataset', 'method'])\\\n",
    "    .agg({'fitness': ['mean', 'std'], 'Performance': ['mean', 'std'], 'Fairness': ['mean', 'std']})\\\n",
    "    .sort_values(by=['Fitness Rule Abvr', 'dataset', ('fitness','mean')], ascending=False)\n",
    "grouped_results['formatted_fitness'] = grouped_results.apply(lambda row: f\"${row[('fitness', 'mean')]:.3f} (\\pm{row[('fitness', 'std')]:.2f})$\", axis=1)\n",
    "grouped_results['formatted_performance'] = grouped_results.apply(lambda row: f\"${row[('Performance', 'mean')]:.3f} (\\pm{row[('Performance', 'std')]:.2f})$\", axis=1)\n",
    "grouped_results['formatted_fairness'] = grouped_results.apply(lambda row: f\"${row[('Fairness', 'mean')]:.3f} (\\pm{row[('Fairness', 'std')]:.2f})$\", axis=1)\n",
    "grouped_results = grouped_results.sort_values(by=['Fitness Rule Abvr', 'dataset'])\n",
    "grouped_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_columns = ['formatted_fitness', 'formatted_performance', 'formatted_fairness']\n",
    "grouped_results[selected_columns].to_latex('tables/grouped_results.tex')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
